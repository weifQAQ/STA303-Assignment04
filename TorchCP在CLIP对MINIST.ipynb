{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d75f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07c83210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from clip import clip\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import scipy.io\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11ba786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "VISUAL_BACKBONE = 'RN50'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load(name=VISUAL_BACKBONE, device=device, download_root='/shareddata/clip/')\n",
    "model.to(device)\n",
    "def model_inference(model, image):\n",
    "    image_embedding = model.encode_image(image)\n",
    "    text_embedding = model.encode_text(text_inputs)\n",
    "    image_embedding /= image_embedding.norm(dim=-1, keepdim=True)\n",
    "    text_embedding /= text_embedding.norm(dim=-1, keepdim=True)\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "    logits = logit_scale * image_embedding @ text_embedding.t()\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10fffd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the zero-shot performance on MNIST  is 11.25%, visual encoder is RN50.\n",
      "the f1 MNIST  is 0.05681565066516961, visual encoder is RN50.\n"
     ]
    }
   ],
   "source": [
    "transform_MNIST_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  \n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),  \n",
    "])\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='/shareddata', train=False,\n",
    "                                       download=True, transform=transform_MNIST_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = [str(i) for i in range(10)]\n",
    "dataset_name = 'MNIST '\n",
    "prompt = 'number' \n",
    "text_inputs = torch.cat([clip.tokenize(f\"{prompt} {c}\") for c in class_names]).to(device)\n",
    "test_targets=[]\n",
    "testing_acc=[]\n",
    "test_preds =[]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch_idx, (images, labels) in enumerate(test_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model_inference(model, images)\n",
    "        _, predicted = logits.max(1)\n",
    "        test_preds.extend(predicted.cpu().tolist())\n",
    "        correct = predicted.eq(labels).sum().item()\n",
    "        acc = correct / labels.size(0)\n",
    "        testing_acc.append(acc)\n",
    "        test_targets.extend(labels.cpu().tolist())\n",
    "    test_f1 = f1_score(test_targets, test_preds, average='weighted')\n",
    "    avg_acc = sum(testing_acc) / len(testing_acc)\n",
    "    print(f\"the zero-shot performance on {dataset_name} is {avg_acc*100:.2f}%, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "    print(f\"the f1 {dataset_name} is {test_f1}, visual encoder is {VISUAL_BACKBONE}.\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c68b1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot performance on MNIST: 11.47%\n",
      "F1 Score on MNIST: 0.0494\n",
      "Score Function: THR, Predictor: SplitPredictor, Coverage Rate: 0.9000, Average Set Size: 8.7136\n",
      "Score Function: THR, Predictor: ClusterPredictor, Coverage Rate: 0.9009, Average Set Size: 8.7182\n",
      "Score Function: THR, Predictor: ClassWisePredictor, Coverage Rate: 0.9004, Average Set Size: 7.5346\n",
      "Score Function: APS, Predictor: SplitPredictor, Coverage Rate: 0.9002, Average Set Size: 8.8408\n",
      "Score Function: APS, Predictor: ClusterPredictor, Coverage Rate: 0.9011, Average Set Size: 8.8405\n",
      "Score Function: APS, Predictor: ClassWisePredictor, Coverage Rate: 0.8970, Average Set Size: 8.4201\n",
      "Score Function: SAPS, Predictor: SplitPredictor, Coverage Rate: 0.9032, Average Set Size: 8.8980\n",
      "Score Function: SAPS, Predictor: ClusterPredictor, Coverage Rate: 0.8995, Average Set Size: 8.8528\n",
      "Score Function: SAPS, Predictor: ClassWisePredictor, Coverage Rate: 0.8966, Average Set Size: 8.6131\n",
      "Score Function: RAPS, Predictor: SplitPredictor, Coverage Rate: 0.8998, Average Set Size: 8.8524\n",
      "Score Function: RAPS, Predictor: ClusterPredictor, Coverage Rate: 0.9001, Average Set Size: 8.8408\n",
      "Score Function: RAPS, Predictor: ClassWisePredictor, Coverage Rate: 0.9029, Average Set Size: 8.5760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchcp.classification.scores import THR, APS, SAPS, RAPS\n",
    "from torchcp.classification.predictors import SplitPredictor, ClusterPredictor, ClassWisePredictor\n",
    "from sklearn.metrics import f1_score\n",
    "from clip import load as clipload, tokenize\n",
    "\n",
    "# 定义 CLIP 模型类\n",
    "class CLIPModel(nn.Module):\n",
    "    def __init__(self, clip_model, model_device) -> None:\n",
    "        super().__init__()\n",
    "        self.clip_model = clip_model\n",
    "        self.model_device = model_device\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        image_features = self.clip_model.encode_image(x_batch.to(self.model_device))\n",
    "        text_inputs = torch.cat([tokenize(f\"a photo of a {c}\").to(self.model_device) for c in class_names])\n",
    "        text_features = self.clip_model.encode_text(text_inputs)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        logit_scale = self.clip_model.logit_scale.exp()\n",
    "        logits = logit_scale * image_features @ text_features.t()\n",
    "        return logits\n",
    "\n",
    "# 加载 CLIP 模型\n",
    "model_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "clip, preprocess = clipload(name=VISUAL_BACKBONE, device=model_device, download_root='/shareddata/clip/')\n",
    "model = CLIPModel(clip, model_device).to(model_device)\n",
    "# 准备 MNIST 数据集\n",
    "transform_MNIST_test = transforms.Compose([\n",
    "    transforms.Resize(size=224),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform_MNIST_test)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# 使用测试集进行预测和评估\n",
    "test_targets = []\n",
    "testing_acc = []\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch_idx, (images, labels) in enumerate(test_dataloader):\n",
    "        images = images.to(model_device)\n",
    "        labels = labels.to(model_device)\n",
    "\n",
    "        # 使用 CLIP 模型进行预测\n",
    "        logits = model(images)\n",
    "        _, predicted = logits.max(1)\n",
    "\n",
    "        test_preds.extend(predicted.cpu().tolist())\n",
    "        test_targets.extend(labels.cpu().tolist())\n",
    "\n",
    "        correct = predicted.eq(labels).sum().item()\n",
    "        acc = correct / labels.size(0)\n",
    "        testing_acc.append(acc)\n",
    "\n",
    "test_f1 = f1_score(test_targets, test_preds, average='weighted')\n",
    "avg_acc = sum(testing_acc) / len(testing_acc)\n",
    "print(f\"Zero-shot performance on MNIST: {avg_acc*100:.2f}%\")\n",
    "print(f\"F1 Score on MNIST: {test_f1:.4f}\")\n",
    "\n",
    "weight_for_saps = 0.3\n",
    "penalty=0.5\n",
    "score_functions = [THR(), APS(), SAPS(weight=weight_for_saps), RAPS(penalty)]\n",
    "predictors = [SplitPredictor, ClusterPredictor, ClassWisePredictor]  \n",
    "# 用于存储不同组合的性能结果\n",
    "performance_results = []\n",
    "for score_function in score_functions:\n",
    "    for Predictor in predictors:\n",
    "        # 创建预测器实例\n",
    "        predictor = Predictor(score_function=score_function, model=model)\n",
    "\n",
    "        # 校准预测器\n",
    "        predictor.calibrate(test_dataloader, alpha=0.1)\n",
    "\n",
    "        # 使用测试集进行预测和评估\n",
    "        evaluation_results = predictor.evaluate(test_dataloader)\n",
    "        coverage_rate = evaluation_results[\"Coverage_rate\"]\n",
    "        average_size = evaluation_results[\"Average_size\"]\n",
    "\n",
    "        # 记录性能结果\n",
    "        performance_results.append((score_function.__class__.__name__, Predictor.__name__, coverage_rate, average_size))\n",
    "# 打印性能结果\n",
    "for result in performance_results:\n",
    "    print(f\"Score Function: {result[0]}, Predictor: {result[1]}, Coverage Rate: {result[2]:.4f}, Average Set Size: {result[3]:.4f}\")\n",
    "    \n",
    "# 清理 CUDA 缓存\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052bb584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
