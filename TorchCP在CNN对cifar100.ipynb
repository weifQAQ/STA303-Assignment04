{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf9405d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d6f836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform_cifar100_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "#裁剪到相同scale\n",
    "\n",
    "transform_cifar100_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar100_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar100_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = ConvNet()\n",
    "model=model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "def train_batch(model, image, target):\n",
    "    output =  model(image)\n",
    "    loss = criterion(output, target)\n",
    "    return output, loss\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    output =  model(image)\n",
    "    loss = criterion(output, target)\n",
    "    return output, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de897b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30 Train Loss: 0.0154 Acc: 0.2563\n",
      "Train Recall: 0.2563 F1 Score: 0.2469\n",
      "Begin test......\n",
      "Test Loss: 0.0139 Acc: 0.3557\n",
      "Test Recall: 0.3557 F1 Score: 0.3344\n",
      "Epoch: 2/30 Train Loss: 0.0142 Acc: 0.3246\n",
      "Train Recall: 0.2905 F1 Score: 0.2822\n",
      "Begin test......\n",
      "Test Loss: 0.0133 Acc: 0.3769\n",
      "Test Recall: 0.3769 F1 Score: 0.3507\n",
      "Epoch: 3/30 Train Loss: 0.0139 Acc: 0.3414\n",
      "Train Recall: 0.3074 F1 Score: 0.3001\n",
      "Begin test......\n",
      "Test Loss: 0.0140 Acc: 0.3450\n",
      "Test Recall: 0.3450 F1 Score: 0.3229\n",
      "Epoch: 4/30 Train Loss: 0.0138 Acc: 0.3456\n",
      "Train Recall: 0.3170 F1 Score: 0.3101\n",
      "Begin test......\n",
      "Test Loss: 0.0137 Acc: 0.3426\n",
      "Test Recall: 0.3426 F1 Score: 0.3142\n",
      "Epoch: 5/30 Train Loss: 0.0136 Acc: 0.3571\n",
      "Train Recall: 0.3250 F1 Score: 0.3186\n",
      "Begin test......\n",
      "Test Loss: 0.0132 Acc: 0.3701\n",
      "Test Recall: 0.3701 F1 Score: 0.3491\n",
      "Epoch: 6/30 Train Loss: 0.0128 Acc: 0.3907\n",
      "Train Recall: 0.3359 F1 Score: 0.3297\n",
      "Begin test......\n",
      "Test Loss: 0.0121 Acc: 0.4363\n",
      "Test Recall: 0.4363 F1 Score: 0.4305\n",
      "Epoch: 7/30 Train Loss: 0.0127 Acc: 0.3967\n",
      "Train Recall: 0.3446 F1 Score: 0.3387\n",
      "Begin test......\n",
      "Test Loss: 0.0119 Acc: 0.4466\n",
      "Test Recall: 0.4466 F1 Score: 0.4364\n",
      "Epoch: 8/30 Train Loss: 0.0125 Acc: 0.4055\n",
      "Train Recall: 0.3522 F1 Score: 0.3465\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.4535\n",
      "Test Recall: 0.4535 F1 Score: 0.4482\n",
      "Epoch: 9/30 Train Loss: 0.0125 Acc: 0.4136\n",
      "Train Recall: 0.3591 F1 Score: 0.3534\n",
      "Begin test......\n",
      "Test Loss: 0.0119 Acc: 0.4438\n",
      "Test Recall: 0.4438 F1 Score: 0.4377\n",
      "Epoch: 10/30 Train Loss: 0.0124 Acc: 0.4160\n",
      "Train Recall: 0.3647 F1 Score: 0.3592\n",
      "Begin test......\n",
      "Test Loss: 0.0118 Acc: 0.4573\n",
      "Test Recall: 0.4573 F1 Score: 0.4499\n",
      "Epoch: 11/30 Train Loss: 0.0119 Acc: 0.4398\n",
      "Train Recall: 0.3716 F1 Score: 0.3661\n",
      "Begin test......\n",
      "Test Loss: 0.0114 Acc: 0.4736\n",
      "Test Recall: 0.4736 F1 Score: 0.4694\n",
      "Epoch: 12/30 Train Loss: 0.0118 Acc: 0.4486\n",
      "Train Recall: 0.3780 F1 Score: 0.3725\n",
      "Begin test......\n",
      "Test Loss: 0.0113 Acc: 0.4728\n",
      "Test Recall: 0.4728 F1 Score: 0.4631\n",
      "Epoch: 13/30 Train Loss: 0.0117 Acc: 0.4502\n",
      "Train Recall: 0.3835 F1 Score: 0.3781\n",
      "Begin test......\n",
      "Test Loss: 0.0111 Acc: 0.4830\n",
      "Test Recall: 0.4830 F1 Score: 0.4780\n",
      "Epoch: 14/30 Train Loss: 0.0117 Acc: 0.4544\n",
      "Train Recall: 0.3886 F1 Score: 0.3832\n",
      "Begin test......\n",
      "Test Loss: 0.0111 Acc: 0.4883\n",
      "Test Recall: 0.4883 F1 Score: 0.4867\n",
      "Epoch: 15/30 Train Loss: 0.0115 Acc: 0.4603\n",
      "Train Recall: 0.3934 F1 Score: 0.3881\n",
      "Begin test......\n",
      "Test Loss: 0.0108 Acc: 0.5001\n",
      "Test Recall: 0.5001 F1 Score: 0.4882\n",
      "Epoch: 16/30 Train Loss: 0.0112 Acc: 0.4796\n",
      "Train Recall: 0.3988 F1 Score: 0.3935\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.5197\n",
      "Test Recall: 0.5197 F1 Score: 0.5131\n",
      "Epoch: 17/30 Train Loss: 0.0111 Acc: 0.4829\n",
      "Train Recall: 0.4037 F1 Score: 0.3985\n",
      "Begin test......\n",
      "Test Loss: 0.0106 Acc: 0.5221\n",
      "Test Recall: 0.5221 F1 Score: 0.5226\n",
      "Epoch: 18/30 Train Loss: 0.0110 Acc: 0.4856\n",
      "Train Recall: 0.4083 F1 Score: 0.4031\n",
      "Begin test......\n",
      "Test Loss: 0.0104 Acc: 0.5221\n",
      "Test Recall: 0.5221 F1 Score: 0.5180\n",
      "Epoch: 19/30 Train Loss: 0.0110 Acc: 0.4884\n",
      "Train Recall: 0.4125 F1 Score: 0.4073\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5182\n",
      "Test Recall: 0.5182 F1 Score: 0.5119\n",
      "Epoch: 20/30 Train Loss: 0.0110 Acc: 0.4926\n",
      "Train Recall: 0.4165 F1 Score: 0.4114\n",
      "Begin test......\n",
      "Test Loss: 0.0105 Acc: 0.5113\n",
      "Test Recall: 0.5113 F1 Score: 0.5123\n",
      "Epoch: 21/30 Train Loss: 0.0107 Acc: 0.5091\n",
      "Train Recall: 0.4209 F1 Score: 0.4159\n",
      "Begin test......\n",
      "Test Loss: 0.0101 Acc: 0.5336\n",
      "Test Recall: 0.5336 F1 Score: 0.5291\n",
      "Epoch: 22/30 Train Loss: 0.0106 Acc: 0.5097\n",
      "Train Recall: 0.4249 F1 Score: 0.4200\n",
      "Begin test......\n",
      "Test Loss: 0.0102 Acc: 0.5350\n",
      "Test Recall: 0.5350 F1 Score: 0.5315\n",
      "Epoch: 23/30 Train Loss: 0.0106 Acc: 0.5074\n",
      "Train Recall: 0.4285 F1 Score: 0.4236\n",
      "Begin test......\n",
      "Test Loss: 0.0101 Acc: 0.5382\n",
      "Test Recall: 0.5382 F1 Score: 0.5335\n",
      "Epoch: 24/30 Train Loss: 0.0106 Acc: 0.5092\n",
      "Train Recall: 0.4319 F1 Score: 0.4270\n",
      "Begin test......\n",
      "Test Loss: 0.0101 Acc: 0.5361\n",
      "Test Recall: 0.5361 F1 Score: 0.5282\n",
      "Epoch: 25/30 Train Loss: 0.0106 Acc: 0.5094\n",
      "Train Recall: 0.4350 F1 Score: 0.4301\n",
      "Begin test......\n",
      "Test Loss: 0.0102 Acc: 0.5325\n",
      "Test Recall: 0.5325 F1 Score: 0.5304\n",
      "Epoch: 26/30 Train Loss: 0.0105 Acc: 0.5178\n",
      "Train Recall: 0.4382 F1 Score: 0.4334\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5467\n",
      "Test Recall: 0.5467 F1 Score: 0.5425\n",
      "Epoch: 27/30 Train Loss: 0.0104 Acc: 0.5209\n",
      "Train Recall: 0.4412 F1 Score: 0.4364\n",
      "Begin test......\n",
      "Test Loss: 0.0099 Acc: 0.5510\n",
      "Test Recall: 0.5510 F1 Score: 0.5461\n",
      "Epoch: 28/30 Train Loss: 0.0104 Acc: 0.5207\n",
      "Train Recall: 0.4441 F1 Score: 0.4393\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5544\n",
      "Test Recall: 0.5544 F1 Score: 0.5495\n",
      "Epoch: 29/30 Train Loss: 0.0104 Acc: 0.5196\n",
      "Train Recall: 0.4467 F1 Score: 0.4420\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5539\n",
      "Test Recall: 0.5539 F1 Score: 0.5471\n",
      "Epoch: 30/30 Train Loss: 0.0103 Acc: 0.5226\n",
      "Train Recall: 0.4492 F1 Score: 0.4445\n",
      "Begin test......\n",
      "Test Loss: 0.0098 Acc: 0.5542\n",
      "Test Recall: 0.5542 F1 Score: 0.5518\n"
     ]
    }
   ],
   "source": [
    "CRtraining_loss = []\n",
    "CRtraining_acc = []\n",
    "CRtesting_loss = []\n",
    "CRtesting_acc = []\n",
    "CRtrain_preds = []\n",
    "CRtrain_targets = []\n",
    "CRtest_preds = []\n",
    "CRtest_targets = []\n",
    "CRtrain_f1_scores = []\n",
    "CRtest_f1_scores = []\n",
    "CRlayer_gradients = [[] for _ in range(len(list(model.parameters())))]\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        CRtrain_preds.extend(preds.cpu().tolist())\n",
    "        CRtrain_targets.extend(target.cpu().tolist())\n",
    "\n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        for i, (name, param) in enumerate(model.named_parameters()):\n",
    "            if param.grad is not None:\n",
    "                CRlayer_gradients[i].append(param.grad.abs().mean().item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    CRtrain_recall = recall_score(CRtrain_targets, CRtrain_preds, average='weighted')\n",
    "    CRtrain_f1 = f1_score(CRtrain_targets, CRtrain_preds, average='weighted')\n",
    "    CRtrain_f1_scores.append(CRtrain_f1)\n",
    "    CRepoch_loss = running_cls_loss / len(train_set)\n",
    "    CRepoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {CRepoch_loss:.4f} Acc: {CRepoch_acc:.4f}')\n",
    "    print(f'Train Recall: {CRtrain_recall:.4f} F1 Score: {CRtrain_f1:.4f}')\n",
    "    CRtraining_loss.append(CRepoch_loss)\n",
    "    CRtraining_acc.append(CRepoch_acc.cpu().detach().numpy())\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "\n",
    "        CRval_loss = 0.0\n",
    "        CRval_corrects = 0\n",
    "        CRtest_preds = []\n",
    "        CRtest_targets = []\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            CRtest_preds.extend(preds.cpu().tolist())\n",
    "            CRtest_targets.extend(target.cpu().tolist())\n",
    "\n",
    "            CRval_loss += loss.item()\n",
    "            CRval_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        CRtest_recall = recall_score(CRtest_targets, CRtest_preds, average='weighted')\n",
    "        CRtest_f1 = f1_score(CRtest_targets, CRtest_preds, average='weighted')\n",
    "        CRtest_f1_scores.append(CRtest_f1)\n",
    "        CRval_loss = CRval_loss / len(test_set)\n",
    "        CRval_acc = CRval_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {CRval_loss:.4f} Acc: {CRval_acc:.4f}')\n",
    "        print(f'Test Recall: {CRtest_recall:.4f} F1 Score: {CRtest_f1:.4f}')\n",
    "        CRtesting_loss.append(CRval_loss)\n",
    "        CRtesting_acc.append(CRval_acc.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189952b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Function: THR, Predictor: SplitPredictor, Coverage Rate: 0.9086, Average Set Size: 3.2963\n",
      "Score Function: THR, Predictor: ClusterPredictor, Coverage Rate: 0.9110, Average Set Size: 3.3260\n",
      "Score Function: THR, Predictor: ClassWisePredictor, Coverage Rate: 0.9069, Average Set Size: 3.3107\n",
      "Score Function: APS, Predictor: SplitPredictor, Coverage Rate: 0.9022, Average Set Size: 3.5150\n",
      "Score Function: APS, Predictor: ClusterPredictor, Coverage Rate: 0.9017, Average Set Size: 3.4846\n",
      "Score Function: APS, Predictor: ClassWisePredictor, Coverage Rate: 0.9038, Average Set Size: 3.5068\n",
      "Score Function: SAPS, Predictor: SplitPredictor, Coverage Rate: 0.9158, Average Set Size: 3.9558\n",
      "Score Function: SAPS, Predictor: ClusterPredictor, Coverage Rate: 0.9170, Average Set Size: 4.0011\n",
      "Score Function: SAPS, Predictor: ClassWisePredictor, Coverage Rate: 0.9137, Average Set Size: 3.9660\n",
      "Score Function: RAPS, Predictor: SplitPredictor, Coverage Rate: 0.9144, Average Set Size: 4.0156\n",
      "Score Function: RAPS, Predictor: ClusterPredictor, Coverage Rate: 0.9147, Average Set Size: 4.0194\n",
      "Score Function: RAPS, Predictor: ClassWisePredictor, Coverage Rate: 0.9128, Average Set Size: 3.8588\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchcp.classification.scores import THR, APS, SAPS, RAPS\n",
    "from torchcp.classification.predictors import SplitPredictor, ClusterPredictor, ClassWisePredictor\n",
    "\n",
    "weight_for_saps = 1.0\n",
    "penalty=0.5\n",
    "score_functions = [THR(), APS(), SAPS(weight=weight_for_saps), RAPS(penalty)]\n",
    "predictors = [SplitPredictor, ClusterPredictor, ClassWisePredictor]  # 假设您已实现 ClusterPredictor\n",
    "\n",
    "# 用于存储不同组合的性能结果\n",
    "performance_results = []\n",
    "\n",
    "for score_function in score_functions:\n",
    "    for Predictor in predictors:\n",
    "        # 创建预测器实例\n",
    "        predictor = Predictor(score_function=score_function, model=model)\n",
    "\n",
    "        # 校准数据集的准备\n",
    "        cal_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "        # 校准预测器\n",
    "        predictor.calibrate(cal_dataloader, alpha=0.1)\n",
    "\n",
    "        # 使用测试集进行预测\n",
    "        predict_sets = []\n",
    "        for images, _ in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            batch_predict_sets = predictor.predict(images)\n",
    "            predict_sets.extend(batch_predict_sets)\n",
    "\n",
    "        # 评估覆盖率和平均集合大小\n",
    "        result_dict = predictor.evaluate(test_dataloader)\n",
    "        coverage_rate, average_size = result_dict[\"Coverage_rate\"], result_dict[\"Average_size\"]\n",
    "        \n",
    "        # 记录性能结果\n",
    "        performance_results.append((score_function.__class__.__name__, Predictor.__name__, coverage_rate, average_size))\n",
    "\n",
    "# 打印性能结果\n",
    "for result in performance_results:\n",
    "    print(f\"Score Function: {result[0]}, Predictor: {result[1]}, Coverage Rate: {result[2]:.4f}, Average Set Size: {result[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231003e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
